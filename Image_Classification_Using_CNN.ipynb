{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d26d2b5-2ad6-41f2-b324-d040fe16a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "from tkinter import Tk, Label, Canvas, Entry, Button, NW\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.preprocessing import image as image_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49756e49-9df7-4c9b-9ee8-dbd998cae7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#------- input layer----\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (128, 128, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# -----------------\n",
    "\n",
    "#--------- hidden layer-------\n",
    "# here 64 is for ascending order in hidden layer (..., 32, 64, 128, 512, ...)\n",
    "# for descending order in hidden layer (..., 512, 128, 64, 32, ...)\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#-------------------------\n",
    "\n",
    "\n",
    "#--- create bridge-------\n",
    "# (for connecting b2n hidden layer and output layer)\n",
    "\n",
    "model.add(Flatten())\n",
    "#------------------\n",
    "\n",
    "#----- output layer-----------\n",
    "# for avoiding problems we will not create output layer directly, So, create FFNN\n",
    "# 128 should be the same or equal to avoid collision\n",
    "\n",
    "model.add(Dense(128, activation = \"relu\")) \n",
    "model.add(Dense(3, activation = \"softmax\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e82885-384c-4ee9-a170-01be07fb33ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= \"adam\",\n",
    "             loss = \"categorical_crossentropy\",\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73a7af3-ff2a-4a72-ade5-72e2cd051bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1.0/255,\n",
    "                                  shear_range = 0.2, \n",
    "                                  zoom_range = 0.2,\n",
    "                                  horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b342a6b7-ade1-4f49-8266-5c8f1693c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "792429d7-b0df-4cc8-88e0-a3bd10b93e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2401 images belonging to 3 classes.\n",
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_datasets = train_datagen.flow_from_directory(\"dataset/training_set\", target_size = (128, 128), batch_size = 32, class_mode = \"categorical\") # local directory\n",
    "testing_datasets = test_datagen.flow_from_directory(\"dataset/test_set\", target_size = (128, 128), batch_size = 32, class_mode = \"categorical\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4308f5f-422d-4b62-abd3-349951068279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 22s 844ms/step - loss: 1.1111 - accuracy: 0.3675 - val_loss: 1.0419 - val_accuracy: 0.4196\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 21s 820ms/step - loss: 1.0039 - accuracy: 0.4737 - val_loss: 0.9371 - val_accuracy: 0.5268\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 20s 801ms/step - loss: 0.9493 - accuracy: 0.5263 - val_loss: 0.9158 - val_accuracy: 0.5670\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 21s 816ms/step - loss: 0.9640 - accuracy: 0.5254 - val_loss: 1.0009 - val_accuracy: 0.4643\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 21s 825ms/step - loss: 0.8809 - accuracy: 0.5813 - val_loss: 0.7821 - val_accuracy: 0.5982\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 20s 802ms/step - loss: 0.8581 - accuracy: 0.5675 - val_loss: 0.7940 - val_accuracy: 0.6161\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 20s 791ms/step - loss: 0.8008 - accuracy: 0.6281 - val_loss: 0.9973 - val_accuracy: 0.5580\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 21s 824ms/step - loss: 0.9387 - accuracy: 0.5587 - val_loss: 0.7833 - val_accuracy: 0.6786\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 20s 800ms/step - loss: 0.8127 - accuracy: 0.6225 - val_loss: 0.7646 - val_accuracy: 0.6696\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 19s 774ms/step - loss: 0.7403 - accuracy: 0.6658 - val_loss: 0.7586 - val_accuracy: 0.6741\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 20s 777ms/step - loss: 1.1163 - accuracy: 0.5215 - val_loss: 0.9196 - val_accuracy: 0.5580\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 22s 893ms/step - loss: 0.9210 - accuracy: 0.5527 - val_loss: 0.9850 - val_accuracy: 0.4955\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 23s 910ms/step - loss: 0.8448 - accuracy: 0.5750 - val_loss: 0.7717 - val_accuracy: 0.6607\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 21s 836ms/step - loss: 0.7510 - accuracy: 0.6606 - val_loss: 0.8533 - val_accuracy: 0.6071\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 21s 835ms/step - loss: 0.7453 - accuracy: 0.6587 - val_loss: 0.6547 - val_accuracy: 0.7366\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 20s 791ms/step - loss: 0.6899 - accuracy: 0.6925 - val_loss: 0.8926 - val_accuracy: 0.6071\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 20s 795ms/step - loss: 0.7087 - accuracy: 0.7063 - val_loss: 0.7569 - val_accuracy: 0.6875\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 21s 819ms/step - loss: 0.6262 - accuracy: 0.7300 - val_loss: 0.6519 - val_accuracy: 0.7411\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 20s 797ms/step - loss: 0.6380 - accuracy: 0.7262 - val_loss: 0.5545 - val_accuracy: 0.7411\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 20s 815ms/step - loss: 0.6167 - accuracy: 0.7513 - val_loss: 0.6163 - val_accuracy: 0.7455\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 20s 795ms/step - loss: 0.5662 - accuracy: 0.7568 - val_loss: 0.6527 - val_accuracy: 0.7723\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 20s 802ms/step - loss: 0.5848 - accuracy: 0.7588 - val_loss: 0.5453 - val_accuracy: 0.7589\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 20s 791ms/step - loss: 0.5415 - accuracy: 0.7850 - val_loss: 0.7180 - val_accuracy: 0.7500\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 21s 822ms/step - loss: 0.5999 - accuracy: 0.7563 - val_loss: 0.6451 - val_accuracy: 0.7455\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 20s 802ms/step - loss: 0.5778 - accuracy: 0.7538 - val_loss: 0.6261 - val_accuracy: 0.7634\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 20s 812ms/step - loss: 0.5087 - accuracy: 0.7925 - val_loss: 0.5452 - val_accuracy: 0.7857\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 20s 806ms/step - loss: 0.4293 - accuracy: 0.8238 - val_loss: 0.5143 - val_accuracy: 0.8170\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 22s 863ms/step - loss: 0.5112 - accuracy: 0.7900 - val_loss: 0.6088 - val_accuracy: 0.7812\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 21s 847ms/step - loss: 0.4474 - accuracy: 0.8175 - val_loss: 0.5105 - val_accuracy: 0.8125\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 20s 804ms/step - loss: 0.6149 - accuracy: 0.7308 - val_loss: 0.7995 - val_accuracy: 0.6295\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 21s 826ms/step - loss: 0.5538 - accuracy: 0.7600 - val_loss: 0.5191 - val_accuracy: 0.8170\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 20s 801ms/step - loss: 0.4866 - accuracy: 0.8150 - val_loss: 0.7808 - val_accuracy: 0.6830\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 20s 781ms/step - loss: 0.4923 - accuracy: 0.7958 - val_loss: 0.5314 - val_accuracy: 0.8036\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 21s 850ms/step - loss: 0.4463 - accuracy: 0.8050 - val_loss: 0.4466 - val_accuracy: 0.8214\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 20s 780ms/step - loss: 0.4573 - accuracy: 0.8140 - val_loss: 0.5453 - val_accuracy: 0.7902\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 21s 818ms/step - loss: 0.3808 - accuracy: 0.8650 - val_loss: 0.5326 - val_accuracy: 0.8080\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 21s 831ms/step - loss: 0.3729 - accuracy: 0.8425 - val_loss: 0.6010 - val_accuracy: 0.7768\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 21s 831ms/step - loss: 0.4080 - accuracy: 0.8325 - val_loss: 0.4800 - val_accuracy: 0.8036\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 21s 812ms/step - loss: 0.3551 - accuracy: 0.8662 - val_loss: 0.3529 - val_accuracy: 0.8795\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 21s 838ms/step - loss: 0.4150 - accuracy: 0.8500 - val_loss: 0.4462 - val_accuracy: 0.8482\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 21s 826ms/step - loss: 0.3933 - accuracy: 0.8425 - val_loss: 0.4986 - val_accuracy: 0.8170\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 20s 782ms/step - loss: 0.4049 - accuracy: 0.8413 - val_loss: 0.4756 - val_accuracy: 0.8438\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 23s 937ms/step - loss: 0.3755 - accuracy: 0.8637 - val_loss: 0.4833 - val_accuracy: 0.7812\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 22s 871ms/step - loss: 0.2961 - accuracy: 0.8788 - val_loss: 0.5444 - val_accuracy: 0.8259\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 21s 827ms/step - loss: 0.3733 - accuracy: 0.8600 - val_loss: 0.4884 - val_accuracy: 0.8348\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 20s 799ms/step - loss: 0.3817 - accuracy: 0.8609 - val_loss: 0.4673 - val_accuracy: 0.8036\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 20s 802ms/step - loss: 0.3677 - accuracy: 0.8600 - val_loss: 0.5994 - val_accuracy: 0.7902\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 19s 772ms/step - loss: 0.4260 - accuracy: 0.8322 - val_loss: 0.6922 - val_accuracy: 0.7366\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 20s 796ms/step - loss: 0.4198 - accuracy: 0.8350 - val_loss: 0.6686 - val_accuracy: 0.7679\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 20s 805ms/step - loss: 0.4346 - accuracy: 0.8225 - val_loss: 0.4227 - val_accuracy: 0.8393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x281c5924a00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_datasets, steps_per_epoch= 800/32, epochs = 50, validation_data = testing_datasets, validation_steps = 200/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b7e288e-75ca-4456-b529-eed4181605f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"model/model.h5\")\n",
    "model.save_weights(\"model/model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b79ed2ea-ad15-41cc-996d-8800b5542edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width, image_height = 128, 128\n",
    "model_path = \"model/model.h5\"\n",
    "model_weight_path = \"model/model_weights.h5\"\n",
    "\n",
    "final_model = load_model(model_path)\n",
    "final_model.load_weights(model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92c10c9a-fe61-4223-b3c3-41b4973b0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ''\n",
    "window = Tk()\n",
    "window.title(\"Image Classification Using CNN\")\n",
    "window.geometry(\"800x800\")\n",
    "\n",
    "label = Label(window, text = \"Please enter Url\", font = (\"Halvetica\", 16))\n",
    "label.pack()\n",
    "\n",
    "\n",
    "def Enter_Url():\n",
    "    global url\n",
    "    label.configure()\n",
    "    url = (User_input.get())\n",
    "    print(url)\n",
    "    \n",
    "    \n",
    "    response = requests.get(url)\n",
    "    test_image = Image.open(BytesIO(response.content))\n",
    "    put_image = test_image.resize((400, 400))\n",
    "    test_image = test_image.resize((128, 128))\n",
    "    \n",
    "    \n",
    "    img = ImageTk.PhotoImage(put_image)\n",
    "    pic = Label(image = img)\n",
    "    pic.pack()\n",
    "    \n",
    "    pic.image = img\n",
    "    test_image = image_utils.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    \n",
    "    results = model.predict_on_batch(test_image)\n",
    "    \n",
    "    if results[0][0] == 1:\n",
    "        res = \"French Fries\"\n",
    "    elif results[0][1] == 1:\n",
    "        res = \"Pizza\"\n",
    "    elif results[0][2] == 1:\n",
    "        res = \"Samosa\"\n",
    "        \n",
    "        \n",
    "    output = Label(window, text = \"Predicted Results: \"+ res, font = (\"Halvetica\", 16))\n",
    "    output.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90868b10-7f38-4567-b833-aca1cecd9bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://gitanjaliroche.com/wp-content/uploads/2021/01/IMG_2451-2-scaled.jpg\n"
     ]
    }
   ],
   "source": [
    "User_input = Entry()\n",
    "User_input.pack()\n",
    "\n",
    "button = Button(window, text = \"Detect\", font = (\"Halvetica\", 16), command = Enter_Url)\n",
    "button.pack()\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766fbef9-83fb-4d7a-9be3-9dd6ed60168c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
