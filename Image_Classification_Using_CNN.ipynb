{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d26d2b5-2ad6-41f2-b324-d040fe16a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "from tkinter import Tk, Label, Canvas, Entry, Button, NW\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.preprocessing import image as image_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49756e49-9df7-4c9b-9ee8-dbd998cae7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#------- input layer----\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (128, 128, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# -----------------\n",
    "\n",
    "#--------- hidden layer-------\n",
    "# here 64 is for ascending order in hidden layer (..., 32, 64, 128, 512, ...)\n",
    "# for descending order in hidden layer (..., 512, 128, 64, 32, ...)\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#-------------------------\n",
    "\n",
    "\n",
    "#--- create bridge-------\n",
    "# (for connecting b2n hidden layer and output layer)\n",
    "\n",
    "model.add(Flatten())\n",
    "#------------------\n",
    "\n",
    "#----- output layer-----------\n",
    "# for avoiding problems we will not create output layer directly, So, create FFNN\n",
    "# 128 should be the same or equal to avoid collision\n",
    "\n",
    "model.add(Dense(128, activation = \"relu\")) \n",
    "model.add(Dense(3, activation = \"softmax\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e82885-384c-4ee9-a170-01be07fb33ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= \"adam\",\n",
    "             loss = \"categorical_crossentropy\",\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73a7af3-ff2a-4a72-ade5-72e2cd051bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1.0/255,\n",
    "                                  shear_range = 0.2, \n",
    "                                  zoom_range = 0.2,\n",
    "                                  horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b342a6b7-ade1-4f49-8266-5c8f1693c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "792429d7-b0df-4cc8-88e0-a3bd10b93e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 images belonging to 3 classes.\n",
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_datasets = train_datagen.flow_from_directory(\"dataset/training_set\", target_size = (128, 128), batch_size = 32, class_mode = \"categorical\") # local directory\n",
    "testing_datasets = test_datagen.flow_from_directory(\"dataset/test_set\", target_size = (128, 128), batch_size = 32, class_mode = \"categorical\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4308f5f-422d-4b62-abd3-349951068279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 42s 2s/step - loss: 1.1046 - accuracy: 0.3812 - val_loss: 1.0492 - val_accuracy: 0.4062\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 32s 1s/step - loss: 1.0191 - accuracy: 0.4600 - val_loss: 0.8957 - val_accuracy: 0.5446\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.9319 - accuracy: 0.5350 - val_loss: 0.8406 - val_accuracy: 0.5223\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 25s 985ms/step - loss: 0.9524 - accuracy: 0.5000 - val_loss: 0.9088 - val_accuracy: 0.5714\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 23s 932ms/step - loss: 0.8765 - accuracy: 0.5850 - val_loss: 0.7700 - val_accuracy: 0.6116\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 21s 855ms/step - loss: 0.8713 - accuracy: 0.5850 - val_loss: 0.7500 - val_accuracy: 0.6607\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 21s 858ms/step - loss: 0.8089 - accuracy: 0.6137 - val_loss: 0.7166 - val_accuracy: 0.6875\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 21s 826ms/step - loss: 0.8101 - accuracy: 0.6200 - val_loss: 0.7705 - val_accuracy: 0.6429\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 20s 808ms/step - loss: 0.7944 - accuracy: 0.6250 - val_loss: 0.7891 - val_accuracy: 0.6339\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 20s 811ms/step - loss: 0.7784 - accuracy: 0.6425 - val_loss: 0.7591 - val_accuracy: 0.6741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2341b6b7f40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_datasets, steps_per_epoch= 800/32, epochs = 10, validation_data = testing_datasets, validation_steps = 200/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b7e288e-75ca-4456-b529-eed4181605f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"model/model.h5\")\n",
    "model.save_weights(\"model/model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b79ed2ea-ad15-41cc-996d-8800b5542edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width, image_height = 128, 128\n",
    "model_path = \"model/model.h5\"\n",
    "model_weight_path = \"model/model_weights.h5\"\n",
    "\n",
    "final_model = load_model(model_path)\n",
    "final_model.load_weights(model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92c10c9a-fe61-4223-b3c3-41b4973b0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ''\n",
    "window = Tk()\n",
    "window.title(\"Image Classification Using CNN\")\n",
    "window.geometry(\"800x800\")\n",
    "\n",
    "label = Label(window, text = \"Please enter Url\", font = (\"Halvetica\", 16))\n",
    "label.pack()\n",
    "\n",
    "\n",
    "def Enter_Url():\n",
    "    global url\n",
    "    label.configure()\n",
    "    url = (User_input.get())\n",
    "    print(url)\n",
    "    \n",
    "    \n",
    "    response = requests.get(url)\n",
    "    test_image = Image.open(BytesIO(response.content))\n",
    "    put_image = test_image.resize((400, 400))\n",
    "    test_image = test_image.resize((128, 128))\n",
    "    \n",
    "    \n",
    "    img = ImageTk.PhotoImage(put_image)\n",
    "    pic = Label(image = img)\n",
    "    pic.pack()\n",
    "    \n",
    "    pic.image = img\n",
    "    test_image = image_utils.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    \n",
    "    results = model.predict_on_batch(test_image)\n",
    "    \n",
    "    if results[0][0] == 1:\n",
    "        res = \"French Fries\"\n",
    "    elif results[0][1] == 1:\n",
    "        res = \"Pizza\"\n",
    "    elif results[0][2] == 1:\n",
    "        res = \"Samosa\"\n",
    "        \n",
    "        \n",
    "    output = Label(window, text = \"Predicted Results: \"+ res, font = (\"Halvetica\", 16))\n",
    "    output.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90868b10-7f38-4567-b833-aca1cecd9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "User_input = Entry()\n",
    "User_input.pack()\n",
    "\n",
    "button = Button(window, text = \"Detect\", font = (\"Halvetica\", 16), command = Enter_Url)\n",
    "button.pack()\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766fbef9-83fb-4d7a-9be3-9dd6ed60168c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
